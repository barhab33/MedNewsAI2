name: update-news

on:
  schedule:
    - cron: "0 */8 * * *" # every 8 hours
  workflow_dispatch: {}

permissions:
  contents: write
  actions: read
  id-token: write

concurrency:
  group: update-news
  cancel-in-progress: false

jobs:
  run-pipeline:
    runs-on: ubuntu-latest
    env:
      # Bolt DB envs available to all steps:
      VITE_BOLTDATABASE_URL: ${{ secrets.VITE_BOLTDATABASE_URL }}
      VITE_BOLTDATABASE_ANON_KEY: ${{ secrets.VITE_BOLTDATABASE_ANON_KEY }}
      # If any script WRITES to DB (insert/update), add your Service Role:
      SUPABASE_SERVICE_ROLE: ${{ secrets.SUPABASE_SERVICE_ROLE }}
      # AI keys (only if your crawler uses them):
      GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
      GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}

    steps:
      - uses: actions/checkout@v4
        with: { fetch-depth: 0 }

      - uses: actions/setup-node@v4
        with:
          node-version: "20"
          cache: "npm"

      - name: Install deps
        run: npm ci

      # Your crawl step; keep if you have a crawler script.
      - name: Crawl & summarize
        run: node scripts/crawl-supabase.cjs

      - name: Export to public
        run: node scripts/export-to-public.cjs

      - name: Commit & push changes
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add -A
          git commit -m "chore: auto update news [skip ci]" || echo "No changes"
          git push
